{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43224,"status":"ok","timestamp":1708873992343,"user":{"displayName":"Prucs Ákos","userId":"12241478937817497031"},"user_tz":-60},"id":"5o97QRLvzwdZ","outputId":"3dc8b52d-d5be-4ba5-e549-12a7e2dfc810"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n","Collecting transformers\n","  Downloading transformers-4.38.1-py3-none-any.whl (8.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Installing collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.37.2\n","    Uninstalling transformers-4.37.2:\n","      Successfully uninstalled transformers-4.37.2\n","Successfully installed transformers-4.38.1\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flash-attn\n","  Downloading flash_attn-2.5.5.tar.gz (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.1.0+cu121)\n","Collecting einops (from flash-attn)\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash-attn) (23.2)\n","Collecting ninja (from flash-attn)\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n","Building wheels for collected packages: flash-attn\n","  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flash-attn: filename=flash_attn-2.5.5-cp310-cp310-linux_x86_64.whl size=120352304 sha256=e70f2f0d4fae98c9ff9742404f3e067bbae56bd3212578ff81c30f73c5ae1a15\n","  Stored in directory: /root/.cache/pip/wheels/b2/67/52/8b6d5fcffdd9e1ec868f554cdef8f03eedb4bf4dcac852fca2\n","Successfully built flash-attn\n","Installing collected packages: ninja, einops, flash-attn\n","Successfully installed einops-0.7.0 flash-attn-2.5.5 ninja-1.11.1.1\n"]}],"source":["# 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\n","!pip install -U transformers\n","!pip install -q accelerate\n","#!pip install bitsandbytes\n","!pip install flash-attn\n","#!huggingface-cli login\n","\n","from transformers import AutoTokenizer\n","import accelerate\n","import transformers\n","import torch\n","import re\n","\n","token=\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4SAlRBjmz5pi"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","#quantization_config = BitsAndBytesConfig(\n","#    load_in_4bit=True,\n","#    bnb_4bit_use_double_quant=True,\n","#    bnb_4bit_quant_type=\"nf4\",\n","#    bnb_4bit_compute_dtype=torch.bfloat16\n","#)\n","\n","\n","class GemmaInterface():\n","    def __init__(self, token, context_length = 2000):\n","        self.context_length = context_length\n","        self.tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\", token=token)\n","        self.model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\",\n","                                                          device_map=\"auto\",\n"," #                                                         quantization_config=quantization_config,\n","                                                          torch_dtype=torch.float16,\n","                                                          attn_implementation=\"flash_attention_2\",\n","                                                          token=token)\n","\n","\n","\n","    def inference(self, history, sys_msg = \"\") -> str:\n","        history[0] = ('user', sys_msg +'\\n\\n'+ history[0][1])\n","        history = [{'role':'user' if texter=='user' else 'assistant', 'content':message} for texter, message in history]\n","        prompt = self.tokenizer.apply_chat_template(history, tokenize=False, add_generation_prompt=True)\n","        prompt_len = len(prompt)\n","        input_ids = self.tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","        outputs = self.model.generate(input_ids=input_ids.to(self.model.device),\n","                                      max_new_tokens=512,\n","                                      do_sample=True,\n","  #                                    temperature=0.1,\n","                                      top_k=10\n","                                      )\n","        text = self.tokenizer.decode(outputs[0], skip_special_tokens=False, clean_up_tokenization_spaces=True)\n","        text = text[prompt_len:]\n","        text = text.replace('<eos>', '')\n","        return text\n","\n","model = GemmaInterface(token=token)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c3MlVAxW0DCT"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"U_h--xsL0Q7M"},"source":["# REBEL for Relation-Extraction"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1893,"status":"ok","timestamp":1708874223055,"user":{"displayName":"Prucs Ákos","userId":"12241478937817497031"},"user_tz":-60},"id":"8lev6YjB0L5b"},"outputs":[],"source":["from transformers import pipeline\n","\n","triplet_extractor = pipeline('text2text-generation',\n","                             model='Babelscape/rebel-large',\n","                             tokenizer='Babelscape/rebel-large',\n","                             device_map='auto'\n","                             )\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":447,"status":"ok","timestamp":1708874272727,"user":{"displayName":"Prucs Ákos","userId":"12241478937817497031"},"user_tz":-60},"id":"lQRb_7Ph0_IF","outputId":"861bc48d-b6ab-4bcd-c45a-624aa9168494"},"outputs":[{"name":"stdout","output_type":"stream","text":["<s><triplet> Ákos <subj> 2000 <obj> date of birth</s>\n","Ákos date of birth 2000\n"]}],"source":["text = \"My name is Ákos. I was born in 2000.11.14. I like coffee and playing videogames. Coffe is actually made of coffee beans.\"\n","\n","# We need to use the tokenizer manually since we need special tokens.\n","extracted_text = triplet_extractor.tokenizer.batch_decode([triplet_extractor(text, return_tensors=True, return_text=False)[0][\"generated_token_ids\"]])\n","print(extracted_text[0])\n","# Function to parse the generated text and extract the triplets\n","def extract_triplets(text):\n","    triplets = []\n","    relation, subject, relation, object_ = '', '', '', ''\n","    text = text.strip()\n","    current = 'x'\n","    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n","        if token == \"<triplet>\":\n","            current = 't'\n","            if relation != '':\n","                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n","                relation = ''\n","            subject = ''\n","        elif token == \"<subj>\":\n","            current = 's'\n","            if relation != '':\n","                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n","            object_ = ''\n","        elif token == \"<obj>\":\n","            current = 'o'\n","            relation = ''\n","        else:\n","            if current == 't':\n","                subject += ' ' + token\n","            elif current == 's':\n","                object_ += ' ' + token\n","            elif current == 'o':\n","                relation += ' ' + token\n","    if subject != '' and relation != '' and object_ != '':\n","        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n","    return triplets\n","\n","extracted_triplets = extract_triplets(extracted_text[0])\n","for trip in extracted_triplets:\n","    print(trip['head'], trip['type'], trip['tail'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9DiXBpTS2Ana"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMbeBn0AJGbiQcYmPbfBB0/","gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
